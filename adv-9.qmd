---
title: adv-mlm
format: revealjs
slide-number: true
execute:
  echo: true
html:
  code-fold: true
  code-summary: Show the code
---



## Lets get wild

1. Hypothetical-P and Mr.P
2. Multivariate models
3. Mediation
4. Distributional models
5. Missing data
6. Measurement error
7. Meta analysis
8. IRT/Cog models
9. gams! 


```{r, echo = FALSE}
library(tidyverse)
library(tidybayes)
library(brms)
library(modelr)
library(marginaleffects)
```






## Making predictions

We often want to make predictions for different groups or individuals. We make predictions using/borrowing information from other individuals, through partial pooling. This improves our predictions.

Can we improve it further? Do we stick with standard MLM based predictions? What if we want to look at sub samples in our data, especially rarer ones (e.g., gay black republicans) or are we worried some are over-represented (e.g., age and high education/SES)

## Hypothetical groups

```{r}
#| code-fold: true
library(readr)
esm <- read_csv("https://raw.githubusercontent.com/josh-jackson/bayes2022/main/static/Lectures/esm_w1_RENAMED.csv")

esm$PA <- esm$esm.NQ11.w1
esm$W.other <- esm$esm.ST04.w1
esm$ID <- esm$esm.IDnum.w1

mlm.5 <- 
  brm(family = gaussian,
      PA ~ 1 + W.other  + (1 + W.other  | ID),
      prior = c(prior(normal(0, 5), class = Intercept),
                prior(normal(0, 5), class = b),
                prior(normal(10, 1), class = sd, coef = Intercept, group = ID), 
                prior(normal(10, 1), class = sd, coef = W.other, group = ID), 
                prior(exponential(1), class = sigma),
                prior(lkj(10), class = cor)),
      iter = 4000, warmup = 1000, chains = 4, cores = 4,
      sample_prior = TRUE,
      file = "mlm.5",
      backend = "cmdstanr",
      data = esm)

```

----------

Draw from the (assumed gaussian) population distribution of random effects, by asking predictions() to make predictions for new “levels” of the random effects. we will have “integrated out the random effects”

```{r}
#| code-fold: true
predictions(
    mlm.5,
    newdata = datagrid(W.other = 0:1, ID = "ralph"),
    allow_new_levels = TRUE)
```

-----------

Notice the extra uncertainty in the new level compared to standard avg technique

```{r}
#| code-fold: true
predictions(
    mlm.5,
    re_formula = NA,
    newdata = datagrid(W.other = 0:1))
```

Notice the difference even for the same "filled in" ID that there is more uncertainty for an individual than the group average.  
```{r}
#| code-fold: true
predictions(
    mlm.5,
    newdata = datagrid(W.other = 0:1, ID = 10472))
```


## Mr.P

Improving predictions by incorporating outside (of the model) information. MRP = multilevel regression with poststratification

One of the biggest problems with psych data is that it is unrepresentative. (Do you trust undergrads or adults off the street wanting to help science?) 

If we know the distribution of the broader population, we can weight (post-stratify) our results to get more accurate estimates. We take the observed sample to reconstruct the rest of the population

## Mr.P

Mr = Multi-level regression aka MLM P = poststratification, with post for posterior and stratification for stratify.

You take your posterior and make predictions based on different strata

Weighted average of predicted values, where weights are the population shares of each category

## Weighting vs postratifying

Weighting is done all the time with data. It gives more or less "weight" to observations that are over or under sampled. Some people "count" more than others in the service of getting data that represents some population.

Poststratification is similar in that it weights the posterior samples rather than the observations.

Why is this preferred? A few reasons, but mainly one can make generalization to new groups or groups with little data. Rather than weighting those specific (potentially unrepresentative) individuals, partial pooling from other information will help with learning

------------------------------------------------------------------------

What do we need? A reliable data source (such as a census) that gives us the population weights. Data can be re-weighted based on many different categories, not just one: for example, we could post-stratify based on age, education, state of residence, etc.

Don't need to even attempt a representative sample. All we need is a sample that is large and diverse enough + population data (e.g., from the census).

------------------------------------------------------------------------

Estimating the proportion of heterosexual women who kept their maiden name after marriage.

https://www.monicaalexander.com/posts/2019-08-07-mrp/ https://bookdown.org/content/4857/models-with-memory.html#summary-bonus-post-stratification-in-an-example

------------------------------------------------------------------------

```{r}

mrp <- load("mrp.rds")

mrp
```

```{r}


```

------------------------------------------------------------------------

```{r}
cell_counts
```

------------------------------------------------------------------------

```{r}
mlm.mrp <-
  brm(family = binomial,
      kept_name | trials(1) ~ 1 + (1 | age_group) + (1 | decade_married) + (1 | educ_group) + (1 | state_name),
      prior = c(prior(normal(-1, 1), class = Intercept),
                prior(exponential(1), class = sd)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      control = list(adapt_delta = .98),
      data = d,
      backend = "cmdstanr",
      file = "mlm.mrp")
```

------------------------------------------------------------------------

```{r}
summary(mlm.mrp)
```

------------------------------------------------------------------------

```{r}
get_variables(mlm.mrp)
```

------------------------------------------------------------------------

```{r}
#| code-fold: true
#| 
posterior_samples(mlm.mrp) %>% 
  select(starts_with("sd_")) %>% 
  set_names(str_c("sigma[", c("age", "decade~married", "education", "state"), "]")) %>% 
  pivot_longer(everything()) %>% 
  group_by(name) %>%
  median_qi(.width = seq(from = .70, to = .95, by = .1)) %>%
  
  ggplot(aes(x = value, xmin = .lower, xmax = .upper, y = reorder(name, value))) +
  geom_interval(aes(alpha = .width), color = "orange3") +
  scale_y_discrete(labels = ggplot2:::parse_safe) +
  scale_alpha_continuous("CI width", range = c(.7, .15)) +
  xlim(0, NA) +
  theme(axis.text.y = element_text(hjust = 0),
        panel.grid.major.y = element_blank())
```

------------------------------------------------------------------------

Census data we will use to make predictions. We will make predictions for every combination of variable we are interested in (state, age, decade married, edu)

```{r}
#| code-fold: true
age_prop <- 
  cell_counts %>% 
  group_by(age_group) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup()

age_prop
```

------------------------------------------------------------------------

```{r}
p <- mlm.mrp %>% 
  add_predicted_draws(newdata = age_prop %>% 
                        filter(age_group > 20, 
                               age_group < 80, 
                               decade_married > 1969),
                      allow_new_levels = T)
p

```

6,058 census categories \* 4,000 samples = 24,232,000

------------------------------------------------------------------------

If we group the results by age_group and .draw, we can sum the product of the posterior predictions and the weights (prop), which will leave us with 4,000 stratified posterior draws for each of the 11 levels of age_group

$$\frac{\sum_i N_i p_i}{\sum_i N_i}$$

------------------------------------------------------------------------

```{r}
#| code-fold: true
pp <-
  p %>% 
  group_by(age_group, .draw) %>% 
  summarise(kept_name_predict = sum(.prediction * prop)) %>% 
  group_by(age_group) %>% 
  mean_qi(kept_name_predict)

pp
```

------------------------------------------------------------------------

```{r}
#| code-fold: true

library(patchwork)
levels <- c("raw data", "multilevel", "MRP")

p1 <-
  # compute the proportions from the data
  d %>% 
  group_by(age_group, kept_name) %>%
  summarise(n = n()) %>% 
  group_by(age_group) %>% 
  mutate(prop = n/sum(n),
         type = factor("raw data", levels = levels)) %>% 
  filter(kept_name == 1, age_group < 80, age_group > 20) %>%
  ggplot(aes(x = prop, y = age_group)) + 
  geom_point() +
  scale_x_continuous(breaks = c(0, .5, 1), limits = c(0, 1)) +
  facet_wrap(~type)


nd <- distinct(d, age_group) %>% arrange(age_group)

p2 <-
  fitted(mlm.mrp,
         re_formula = ~ (1 | age_group),
         newdata = nd) %>% 
  data.frame() %>% 
  bind_cols(nd) %>% 
  mutate(prop = Estimate,
         type = factor("multilevel", levels = levels)) %>% 
  
  ggplot(aes(x = prop, xmin = Q2.5, xmax = Q97.5, y = age_group)) + 
  geom_pointrange(color = "blue2", size = 0.8, fatten = 2) +
  scale_x_continuous(breaks = c(0, .5, 1), limits = c(0, 1)) +
  scale_y_discrete(labels = NULL) +
  facet_wrap(~type)


p3 <-
  pp %>%
  mutate(type = factor("MRP", levels = levels)) %>% 
  ggplot(aes(x = kept_name_predict, xmin = .lower, xmax = .upper, y = age_group)) + 
  geom_pointrange(color = "orange2", size = 0.8, fatten = 2) +
  scale_x_continuous(breaks = c(0, .5, 1), limits = c(0, 1)) +
  scale_y_discrete(labels = NULL) +
  facet_wrap(~type)

# combine!
(p1 | p2 | p3) +
  plot_annotation(title = "Proportion of women keeping name after marriage, by age")

```

------------------------------------------------------------------------

Can also be done simply in {marginaleffects}

```{r, eval = FALSE}
p <- predictions(  # Compute predictions,
    model = mod, # using the mlm model `mod`, 
    newdata = stratification, # for each row of the `stratification` table.
    by = "age", #select which grouping variable
    wts = "proportion") #weight them
```


## Mr.P Not limited to surveys

Example (using brms) with experimental data -- can you generalize from your sample of undergraduates to other undergraduates at your university, let alone undergraduates in general, let alone young adults, to say nothing about the population of humans. https://arxiv.org/pdf/1906.11323.pdf

More info: https://marginaleffects.com/articles/mrp.html

## recent example

https://osf.io/preprints/psyarxiv/fcm3n/

![](mrp.png)



## Multivariate models

Any model that has more than 1 DV. While common within SEM frameworks, multivariate models are not often used within standard linear modeling (outside of MANOVA), mostly because of computational difficulties. 

When do you want to use multivariate models? All the time! Mediation, path models, distributional models, IRT models, parallel process MLMs, etc etc. 
What are advantages? Fewer models than doing separate, additional parameters, novel Qs. 

We've already done one of these: the multinomial logistic


## multivariate MLMs

```{r}
library(brms)
library(tidyverse)
library(tidybayes)
library(modelr)

data <- "https://raw.githubusercontent.com/josh-jackson/bayes/master/mlm.csv"
mlm <- read.csv(data) 
```


```{r}
mv.1 <- 
  brm(family = gaussian,
      mvbind(CON, DAN) ~ 1 + time + (1 + time | ID),
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 1.5), class = b),
                prior(lkj(2), class = cor),
                prior(lkj(2), class = rescor)),
      iter = 4000, warmup = 1000, chains = 4, cores = 4,
      file = "mv.1",
      backend = "cmdstanr",
      data = mlm)


```


---

```{r}
summary(mv.1)
```


---

```{r}
fixef(mv.1)
```

```{r}
mv.1 %>% 
  gather_draws(sd_ID__CON_Intercept, sd_ID__CON_time, sd_ID__DAN_Intercept, sd_ID__DAN_time, cor_ID__CON_Intercept__CON_time, cor_ID__DAN_Intercept__DAN_time, rescor__CON__DAN) %>% 
   median_qi()
```

---

```{r}
#| code-fold: true
mv.1 %>% 
  spread_draws(sd_ID__CON_time) %>% 
  ggplot(aes( x = sd_ID__CON_time))+
  stat_halfeye()
```


## correlation between slopes

```{r}
#| code-fold: true
library(correlation)

CON_slope <- mv.1 %>% 
spread_draws(r_ID__CON[ID,time]) %>% 
  filter(time == "time") %>% 
  group_by(ID) %>% 
  median_qi(r_ID__CON) %>% 
  select(ID, r_ID__CON)

DAN_slope <- mv.1 %>% 
spread_draws(r_ID__DAN[ID,time]) %>% 
  filter(time == "time") %>% 
  group_by(ID) %>% 
  median_qi(r_ID__DAN) %>% 
  select(ID, r_ID__DAN)

slope_cor<- left_join(CON_slope,DAN_slope)
plot(cor_test(slope_cor, "r_ID__CON", "r_ID__DAN"))
```


## Everything is SEM

Structural equation modeling (SEM) is the most popular way to handle multiple DVs. SEM is also known as covariance structure analysis, which really means unstandardized correlations. We can fit some simple SEM models using brms! 

Also, SEM is really regression but a broader form. Also SEM can be equivalent to MLM in many respects.  



## correlations (as multivariate models)


```{r}

mv.1c <- 
  brm(family = gaussian,
      bf(mvbind(CON, DAN) ~ 1) +
      set_rescor(TRUE),
      prior = c(prior(normal(0, 1.5), class = Intercept, resp = CON),
                prior(normal(0, 1.5), class = Intercept, resp = DAN),
                prior(normal(0, 1.5), class = sigma, resp = CON),
                prior(normal(0, 1.5), class = sigma, resp = DAN),
                prior(lkj(2), class = rescor)),
      iter = 4000, warmup = 1000, chains = 4, cores = 4,
      file = "mv.1c",
      backend = "cmdstanr",
      data = mlm)


```


---

```{r}
summary(mv.1c)
```


---

```{r}
mv.1c %>% 
  spread_draws(rescor__CON__DAN) %>% 
  mean_qi()
```

```{r}
cor(mlm$CON, mlm$DAN)
```


---

Make it robust

```{r}

mv.1cr <- 
  brm(family = student,
      bf(mvbind(CON, DAN) ~ 1) +
      set_rescor(TRUE),
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 1.5), class = Intercept, resp = CON),
                prior(normal(0, 1.5), class = Intercept, resp = DAN),
                prior(normal(0, 1.5), class = sigma, resp = CON),
                prior(normal(0, 1.5), class = sigma, resp = DAN),
                prior(lkj(2), class = rescor)),
      iter = 4000, warmup = 1000, chains = 4, cores = 4,
      file = "mv.1cr",
      backend = "cmdstanr",
      data = mlm)

```


---

```{r}
summary(mv.1cr)
```

---

```{r}
#| code-fold: true
library(patchwork)
g1 <- mv.1c %>% 
  spread_draws(rescor__CON__DAN) %>% 
   ggplot(aes( x = rescor__CON__DAN))+
    stat_pointinterval() +xlim(.1,.4)

g2 <- mv.1cr %>% 
  spread_draws(rescor__CON__DAN) %>% 
   ggplot(aes( x = rescor__CON__DAN))+
    stat_pointinterval()+xlim(.1,.4)

(g1 / g2)  
```


---

Residual correlations are useful because they can be conceptualized as what is left over in the DV after accounting for your predictors. Or it is a measure of your DV controlling/adjusting for the predictors. 

What can we do with this outside of looking at correlations?



## Simple mediation

$$M  = i_M + a X + e_M$$
$$Y  = i_Y + c' X + b M + e_Y$$




```{r}
#| code-fold: true

library(ggdag)

dag_coords <-
  tibble(name = c("X", "M", "Y"),
         x    = c(1, 2, 3),
         y    = c(2, 1, 2))

p1 <-
  dagify(M ~ X,
       Y ~ X + M,
       coords = dag_coords) %>%
  
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(color = "black", alpha = 1/4, size = 10) +
  geom_dag_text(color = "black") +
  geom_dag_edges(edge_color = "black") +
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_bw() +
  theme(panel.grid = element_blank())+
  ggtitle("direct + indirect effect")

p2 <-
  dagify(Y ~ X,
       coords = dag_coords) %>%
  
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(color = "black", alpha = 1/4, size = 10) +
  geom_dag_text(color = "black") +
  geom_dag_edges(edge_color = "black") +
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_bw() +
  theme(panel.grid = element_blank())+
  ggtitle("Total effect")

library(patchwork)

p2 | p1

```


---

```{r}
#| code-fold: true
#| 
X <- rnorm(100)
M <- 0.5*X + rnorm(100)
Y <- 0.7*M + rnorm(100)
Data <- data.frame(X = X, Y = Y, M = M)

# describe your equations
y_model <- bf(Y ~ 1 + X + M)
m_model <- bf(M ~ 1 + X)

# simultaneously estimate
med.1 <-
  brm(family = gaussian,
      y_model + m_model + set_rescor(FALSE),
      data = Data,
      cores = 4,
      backend = "cmdstanr",
      file = "med.1")

```


---

```{r}
#| code-fold: true
summary(med.1)
```




## Indirect effects

```{r}
#| code-fold: true
library(tidybayes)
get_variables(med.1)
```

```{r}
#| code-fold: true
med.1 %>% 
  spread_draws(b_Y_M, b_M_X,b_Y_X) 

```



## calculate indirect effects

```{r}
#| code-fold: true
med.1 %>% 
  spread_draws(b_Y_M, b_M_X, b_Y_X) %>% 
  mutate(indirect = b_Y_M * b_M_X) %>% 
  mutate(direct = b_Y_X) %>% 
  mutate(total = indirect + direct ) %>% 
  median_qi(indirect, direct,total)
```


---

```{r}
#| code-fold: true
med.1 %>% 
  spread_draws(b_Y_M, b_M_X, b_Y_X) %>% 
  mutate(indirect = b_Y_M * b_M_X) %>% 
  mutate(direct = b_Y_X) %>% 
  mutate(total = indirect + direct ) %>% 
  select(indirect, direct, total) %>% 
  gather() %>% 
  ggplot(aes(y = key, x = value)) +
  stat_dotsinterval()
```



## priors for mediation

7 parameters to estimate

```{r}
#| code-fold: true
med.2 <-
  brm(family = gaussian,
      y_model + m_model + set_rescor(FALSE),
       prior = c(prior(normal(0, 1), class = Intercept, resp = M),
                 prior(normal(0, 1), class = Intercept, resp = Y),
                prior(normal(0, 2), class = b, coef = X, resp = M),
                prior(normal(0, 2), class = b, coef = M, resp = Y),
                prior(normal(0, 2), class = b, coef = X, resp = Y),
                prior(exponential(1), class = sigma, resp = M),
                prior(exponential(1), class = sigma, resp = Y)),
      data = Data,
      cores = 4,
      backend = "cmdstanr",
      file = "med.2")
```

---

```{r}
summary(med.2)
```

---

```{r}
#| code-fold: true
med.2 %>% 
  spread_draws(b_Y_M, b_M_X) %>% 
  mutate(indirect = b_Y_M * b_M_X) %>% 
  median_qi(indirect)
```


```{r}
#| code-fold: true
med.1 %>% 
  spread_draws(b_Y_M, b_M_X) %>% 
  mutate(indirect = b_Y_M * b_M_X) %>% 
  median_qi(indirect)
```



## Multiple Predictors, mediators and outcomes


```{r}
#| code-fold: true
n <- 1e3
set.seed(4.5)
mult.X <-
  tibble(X1 = rnorm(n, mean = 0, sd = 1),
         X2 = rnorm(n, mean = 0, sd = 1),
         X3 = rnorm(n, mean = 0, sd = 1)) %>% 
  mutate(med = rnorm(n, mean = 0 + X1 * -1 + X2 * 0 + X3 * 1, sd = 1),
         dv  = rnorm(n, mean = 0 + X1 * 0 + X2 * .5 + X3 * 1 + M * .5, sd = 1))

```



```{r}
#| code-fold: true
#| 
MultX_coords <-
  tibble(name = c("X1","X2","X3",  "M", "Y"),
         x    = c(1,1,1, 2, 3),
         y    = c(2,1,3, 1, 2))

X1 <-
  dagify(M ~ X1 + X2 + X3,
       Y ~ X1 + X2 + X3 + M,
       coords = MultX_coords) %>%
  
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(color = "black", alpha = 1/4, size = 10) +
  geom_dag_text(color = "black") +
  geom_dag_edges(edge_color = "black") +
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_bw() +
  theme(panel.grid = element_blank())+
  ggtitle("direct + indirect effect")
X1
```


---

```{r}
med.3 <-
  brm(family = gaussian,
      bf(dv ~ 1 + X1 + X2 + X3 + med) + 
        bf(med ~ 1 + X1 + X2 + X3) + 
        set_rescor(FALSE),
      data = mult.X, 
      file = "med.3", 
      backend = "cmdstanr",
      cores = 4)
```

---

```{r}
summary(med.3)
```


```{r}
#| code-fold: true
med.3 %>% 
  spread_draws(b_dv_Intercept, b_med_Intercept, b_dv_X1, b_dv_X2, b_dv_X3, b_dv_med, b_med_X1, b_med_X2, b_med_X3) %>% 
  mutate(indirect1 = b_dv_med * b_med_X1) %>% 
  mutate(indirect2 = b_dv_med * b_med_X2) %>% 
  mutate(indirect3 = b_dv_med * b_med_X3) %>% 
  mutate(direct1 = b_dv_X1) %>% 
  mutate(direct2 = b_dv_X2) %>% 
  mutate(direct3 = b_dv_X3) %>% 
  mutate(total1 = indirect1 + direct1 ) %>% 
  mutate(total2 = indirect2 + direct2 ) %>% 
  mutate(total3 = indirect3 + direct3 ) %>% 
  select(.draw, indirect1:total3) %>% 
  median_qi()
```





## Multiple Outcomes

```{r}
#| code-fold: true
n <- 1e3

set.seed(4.5)
Ys <-
  tibble(X  = rnorm(n, mean = 0, sd = 1)) %>% 
  mutate(M = rnorm(n, mean = 0 + X * .5, sd = 1)) %>% 
  mutate(Y1 = rnorm(n, mean = 0 + X * -1 + M * 0,  sd = 1),
         Y2 = rnorm(n, mean = 0 + X * 0  + M * .5, sd = 1),
         Y3 = rnorm(n, mean = 0 + X * 1  + M * 1,  sd = 1))

```

```{r}
#| code-fold: true
MultY_coords <-
  tibble(name = c("X","M","Y1",  "Y2", "Y3"),
         x    = c(1,2,3, 3, 3),
         y    = c(2,2.25,1, 2, 3))

Y1 <-
  dagify(M ~ X,
       Y1 ~ X +  M,
       Y2 ~ X +  M,
       Y3 ~ X +  M,
       coords = MultY_coords) %>%
  
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(color = "black", alpha = 1/4, size = 10) +
  geom_dag_text(color = "black") +
  geom_dag_edges(edge_color = "black") +
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_bw() +
  theme(panel.grid = element_blank())+
  ggtitle("direct + indirect effect")
Y1

```


---

```{r}
#| code-fold: true
mult.Ys <-
  brm(family = gaussian,
      bf(Y1 ~ 1 + X + M) + 
        bf(Y2 ~ 1 + X + M) + 
        bf(Y3 ~ 1 + X + M) + 
        bf(M ~ 1 + X) + 
        set_rescor(FALSE),
      data = Ys,
      backend = "cmdstanr",
      cores = 4,
      file = "med.4")
```

---

```{r}
#| code-fold: true
summary(mult.Ys)
```



## Multiple Mediators

Note we can compute individual and total indirect effects

```{r}
#| code-fold: true
parallel <-
  tibble(name = c("X","M1","M2",  "Y"),
         x    = c(1,2,2,3),
         y    = c(2,2.25,1.75, 2))


 X2<- dagify(M1 ~ X,
       M2 ~ X ,
       Y ~ X +  M1,
       Y ~ X +  M2,
       coords = parallel) %>%
  
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(color = "black", alpha = 1/4, size = 10) +
  geom_dag_text(color = "black") +
  geom_dag_edges(edge_color = "black") +
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_bw() +
  theme(panel.grid = element_blank())+
  ggtitle("parallel")
 
 
 serial <-
  tibble(name = c("X","M1","M2",  "Y"),
         x    = c(1,1.5,2.5,3),
         y    = c(2,2.25,2.25, 2))
 
  X3<- dagify(M1 ~ X,
       M2 ~ M1 ,
        M2 ~ X ,
       Y ~ M1,
       Y ~ X +  M2,
       coords = serial)  %>%
  
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(color = "black", alpha = 1/4, size = 10) +
  geom_dag_text(color = "black") +
  geom_dag_edges(edge_color = "black") +
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_bw() +
  theme(panel.grid = element_blank())+
  ggtitle("serial")

X2 | X3
```


## parallel

```{r, eval = FALSE}
#| code-fold: true
m1_model <- bf(M1 ~ 1 + X)
m2_model <- bf(M2  ~ 1 + X)
y_model  <- bf(Y ~ 1 + X + M1 + M2)

par <-
  brm(family = gaussian,
      y_model + m1_model + m2_model + set_rescor(FALSE),
      backend = "cmdstanr",
      data = d)
```

3 indirect effects can be calculated


## serial

```{r, eval = FALSE}
#| code-fold: true
ser <-
  brm(family = gaussian,
        bf(M1 ~ 1 + X) + 
        bf(M2 ~ 1 + X + M1) + 
        bf(Y ~ 1 + X + M1 + M2) + 
        set_rescor(FALSE),
      backend = "cmdstanr",
        data=d)

```

4 indirect effects can be calculated


## moderated mediation? 

```{r, eval = FALSE}
#| code-fold: true
#| 
y_model <- bf(Y ~ 1 + X + M)
m_model <- bf(M ~ 1 + X*moderator)

med.5 <-
  brm(family = gaussian,
      y_model + m_model + set_rescor(FALSE),
      data = Data,
      cores = 4,
      backend = "cmdstanr",
      file = "med.5")
```





## Distributional Models

In basic regression with a Gaussian DV, we predict the mean, $\mu$ through some linear model. The second parameter of the normal distribution – the residual standard deviation $\sigma$ – is assumed to be constant across observations. We estimate it but do not predict it.

This extends beyond Gaussian DVs, as most response distributions have a "location" parameter and one or more "scale" or "shape" parameters. Instead of only predicting the location parameters, we can also predict the scale parameters

---

$$y_{ik} \sim normal(\mu_{ik}, \sigma_{ik})$$
$$\mu_{ik} = \beta_0 + \beta_1 Group_{ik}$$
$$\sigma_{ik} = \gamma_0 + \gamma_1 Group_{ik}$$

---

```{r}
#| code-fold: true
d.1a <- 
  brm(family = student,
     bf( CON ~ 0 + group,
         sigma ~ 0 + group),
                file = "d.1a",
                backend = "cmdstanr",
                data = mlm)

```

---

```{r}
#| code-fold: true
summary(d.1a)
```

---

```{r}
d.1b <- 
  brm(family = gaussian,
     bf( CON ~ 1 + group,
         sigma ~ 1 + group),
                file = "d.1b",
                backend = "cmdstanr",
                data = mlm)
```

---

```{r}
summary(d.1b)
```


---

```{r}
d.2 <- 
  brm(family = gaussian,
     bf( CON ~ 1 + group,
         sigma ~ 1 + group*Education),
                file = "d.2",
                 backend = "cmdstanr",
                data = mlm)
```


---

```{r}
summary(d.2)
```

---

```{r}
#| code-fold: true
d.1a %>% 
  gather_draws(b_sigma_groupCTRL, b_sigma_groupPD) %>% 
  ggplot(aes(x = .value, group = .variable,  fill = .variable)) +
  stat_halfeye(alpha = .7)
```

---

```{r}
#| code-fold: true
d.1a %>% 
  gather_draws(b_sigma_groupCTRL, b_sigma_groupPD) %>% 
  mutate(value = exp(.value)) %>% 
  ggplot(aes(x = value, group = .variable,  fill = .variable)) +
  stat_halfeye(alpha = .7)
```


---

But these are estimates of the parameter, not spread in the groups. Can we have a plot that includes variances and means? 

---


```{r}
mlm %>% 
  data_grid(group = group) %>% 
  add_predicted_draws(d.1a) %>% 
  ggplot(aes(x = .prediction, group =  fct_rev(group), fill = fct_rev(group))) +
  stat_halfeye(alpha = .6)
```



## distributional MLM models


```{r}
#| code-fold: true
set.seed(16)
melsm %>% 
  ungroup() %>% 
  nest(data = !record_id) %>% 
  slice_sample(n = 12) %>% 
  unnest(data) %>% 
  ggplot(aes(x = day, y = N_A.lag)) +
  geom_line(color = "black") +
  geom_point(color = "black", size = 1/2) +
  ylab("negative affect (standardized)") +
  facet_wrap(~record_id)
```


----------------

standard MLM 

```{r}
#| code-fold: true
melsm.1 <-
  brm(family = gaussian,
      N_A.std ~ 1 + day01 + (1 + day01 | record_id),
      prior = c(prior(normal(0, 0.2), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(exponential(1), class = sd),
                prior(exponential(1), class = sigma),
                prior(lkj(2), class = cor)),
      iter = 3000, warmup = 1000, chains = 4, cores = 4,
      data = melsm,
      backend = "cmdstanr",
      file = "melsm.1")
```


---

```{r}
summary(melsm.1)
```






## MLM assumptions


Sigma, which captures the variation in NA not accounted for by the intercepts, time predictor, and the correlation. An assumption is that sigma does NOT vary across persons, occasions, or other variables. 

Posterior predictive interval is the same across people even though it seems inappropriate from person to person

-----


```{r}
#| code-fold: true
newd <-
  melsm %>% 
  filter(record_id %in% c(30, 115)) %>% 
  select(record_id, N_A.std, day01)

fits <- newd %>%
  add_epred_draws(melsm.1)

preds <- newd %>%
  add_predicted_draws(melsm.1)

fits %>% 
ggplot(aes(x = day01, y = N_A.std)) +
  stat_lineribbon(aes(y = .epred),.width = c(.95), alpha = 1/4, color ="grey") +
  stat_lineribbon(data = preds, aes(y = .prediction),.width = c(.90), alpha = 1/4, color ="blue") +
  geom_point(data = newd) +
  facet_wrap(~record_id)
```




---


$$NA_{ij} \sim \operatorname{Normal}(\mu_{ij}, \sigma_{i})$$

$$\mu_{ij}  = \beta_0 + \beta_1 time_{ij} + u_{0i} + u_{1i} time_{ij}$$
$$\log(\sigma_i )  = \eta_0 + u_{2i}$$

$$\begin{bmatrix} u_{0i} \\ u_{1i} \\ {u_{2i}} \end{bmatrix}  \sim \operatorname{MVNormal}\begin{pmatrix} \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}, \mathbf S \mathbf R \mathbf S \end{pmatrix}$$
$$\mathbf S  = \begin{bmatrix} \sigma_0 & 0 & 0 \\ 0 & \sigma_1 & 0 \\ 0 & 0 & \sigma_2 \end{bmatrix}$$
$$\mathbf R = \begin{bmatrix} 1 & \rho_{12} & \rho_{13} \\ \rho_{21} & 1 & \rho_{23} \\ \rho_{31} & \rho_{32} & 1 \end{bmatrix}$$
$$\beta_0  \sim \operatorname{Normal}(0, 0.2)$$
$$\beta_1 \text{and } \eta_0  \sim \operatorname{Normal}(0, 1) $$
$$ \sigma_0,\dots, \sigma_2 \sim \operatorname{Exponential}(1) $$
$$\mathbf R  \sim \operatorname{LKJ}(2)$$


---

note: 1) brms default is to use log-link when modeling sigma
2) |i| syntax within the parentheses allow for correlated random effects. Without this, the random intercept and slope would not be correlated with the random sigma term, effectively setting the correlation equal to zero 

```{r}
#| code-fold: true
melsm.2 <-
  brm(family = gaussian,
      bf(N_A.std ~ 1 + day01 + (1 + day01 |i| record_id),
         sigma ~ 1 + (1 |i| record_id)),
                prior = c(prior(normal(0, 0.2), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(exponential(1), class = sd),
                prior(normal(0, 1), class = Intercept, dpar = sigma),
                prior(exponential(1), class = sd, dpar = sigma),
                prior(lkj(2), class = cor)),
      iter = 3000, warmup = 1000, chains = 4, cores = 4,
      data = melsm,
      backend = "cmdstanr",
      file = "melsm.2")
```

---

No sigma - location covariance

```{r, eval = FALSE}
#| code-fold: true
melsm.2 <-
  brm(family = gaussian,
      bf(N_A.std ~ 1 + day01 + (1 + day01 | record_id),
         sigma ~ 1 + (1 | record_id)),
                prior = c(prior(normal(0, 0.2), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(exponential(1), class = sd),
                prior(normal(0, 1), class = Intercept, dpar = sigma),
                prior(exponential(1), class = sd, dpar = sigma),
                prior(lkj(2), class = cor)),
      iter = 3000, warmup = 1000, chains = 4, cores = 4,
      data = melsm,
      backend = "cmdstanr",
      file = "melsm.2")
```
 
 
------


```{r}
#| code-fold: true
summary(melsm.2)
```


---

```{r}
#| code-fold: true
melsm.2 %>% 
  spread_draws(b_sigma_Intercept) %>% 
  exp() %>% 
  median_qi()
```

```{r}
#| code-fold: true
melsm.2 %>% 
  spread_draws(b_day01) %>% 
  median_qi()
```


---

```{r}
#| code-fold: true
melsm.2 %>% 
spread_draws(b_sigma_Intercept,r_record_id__sigma[ID, term]) 
```

8000 samples * 193 participants = 1544000 

---


```{r}
#| code-fold: true
melsm.2 %>% 
spread_draws(b_sigma_Intercept,r_record_id__sigma[ID, term]) %>% 
  mutate(b_sigma_Intercept = exp(b_sigma_Intercept)) %>% 
  mutate(r_record_id__sigma = exp(r_record_id__sigma)) %>% 
   median_qi(estimate = b_sigma_Intercept + r_record_id__sigma) %>% 
  ggplot(aes(x = reorder(ID, estimate), y = estimate, ymin = .lower, ymax = .upper)) +
   geom_pointinterval(point_colour = "black", interval_color = "grey", point_alpha = .25) + scale_x_discrete("Participants ranked by posterior SD", breaks = NULL) + ylab("sigma estimate") + theme_light()
```


---


```{r}
#| code-fold: true
fits2 <- newd %>%
  add_epred_draws(melsm.2)

preds2 <- newd %>%
  add_predicted_draws(melsm.2)

fits2 %>% 
ggplot(aes(x = day01, y = N_A.std)) +
  stat_lineribbon(aes(y = .epred),.width = c(.95), alpha = 1/4, color ="grey") +
  stat_lineribbon(data = preds2, aes(y = .prediction),.width = c(.90), alpha = 1/4, color ="blue") +
  geom_point(data = newd) +
  facet_wrap(~record_id)
```





## time as a predictor of sigma

```{r}
#| code-fold: true
melsm.3 <-
  brm(family = gaussian,
      bf(N_A.std ~ 1 + day01 + (1 + day01 |i| record_id),
         sigma ~ 1 + day01 + (1 + day01 |i| record_id)),
      prior = c(prior(normal(0, 0.2), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(exponential(1), class = sd),
                prior(normal(0, 1), class = Intercept, dpar = sigma),
                prior(normal(0, 1), class = b, dpar = sigma),
                prior(exponential(1), class = sd, dpar = sigma),
                prior(lkj(2), class = cor)),
      iter = 3000, warmup = 1000, chains = 4, cores = 4,
      backend = "cmdstanr",
      data = melsm,
      file = "melsm.3")
```


---




```{r}
#| code-fold: true
summary(melsm.3)
```



---

```{r}
#| code-fold: true
melsm.3 %>% 
  gather_draws(b_sigma_Intercept, b_sigma_day01) %>% 
  median_qi()
```

---

```{r}
#| code-fold: true
melsm.3 %>% 
  spread_draws(b_sigma_Intercept) %>% 
  mutate(sigma_day0 = exp(b_sigma_Intercept)) %>% 
  select(sigma_day0) %>% 
  median_qi()
```

```{r}
#| code-fold: true
melsm.3 %>% 
  spread_draws(b_sigma_Intercept, b_sigma_day01) %>% 
  mutate(sigma_day1 = exp(b_sigma_Intercept + b_sigma_day01)) %>% 
  select(sigma_day1) %>% 
  median_qi()
```

---

```{r}
#| code-fold: true
 melsm %>% 
  data_grid(day01 = seq_range(day01, n = 20), .model = melsm) %>% 
  add_epred_draws(melsm.3, re_formula = NA, dpar = T) %>% 
  ungroup() %>% 
  select(day01, .epred, mu, sigma)
```
20 * 8000 = 160000

---

```{r}
#| code-fold: true
melsm %>% 
  data_grid(day01 = seq_range(day01, n = 20), .model = melsm) %>% 
  add_epred_draws(melsm.3, re_formula = NA, dpar = T) %>% 
  ungroup() %>% 
  select(day01, .epred, sigma) %>% 
  ggplot()+
  aes(x = day01, y = sigma) +
  stat_lineribbon(.width = 0.95, alpha = .5)
```


---

Lets look at random effects. Remember we fit a random effect for both the intercept and the slope (time)

```{r}
#| code-fold: true
melsm.3 %>% 
spread_draws(r_record_id__sigma[ID, term]) %>% 
  mutate(r_record_id__sigma = exp(r_record_id__sigma)) 
```
193 * 8000 *2

---

```{r}
#| code-fold: true
melsm.3 %>% 
spread_draws(b_sigma_Intercept,b_sigma_day01, r_record_id__sigma[ID, term]) %>% 
  pivot_wider(names_from = term, values_from = r_record_id__sigma) %>% 
  mutate(r_sigma_intercept = exp(b_sigma_Intercept + Intercept)) %>% 
  mutate(r_sigma_slope = (b_sigma_day01 + day01)) %>% 
  select(ID, r_sigma_intercept, r_sigma_slope ) %>% 
   median_qi() %>% 
  select(ID, r_sigma_intercept, r_sigma_slope)
```

---


```{r}
melsm.3 %>% 
spread_draws(b_sigma_Intercept, r_record_id__sigma[ID, term]) %>% 
  mutate(r_record_id__sigma = exp(b_sigma_Intercept + r_record_id__sigma)) %>% 
   median_qi(estimate = r_record_id__sigma) %>% 
  filter(term == "Intercept") %>% 
  ggplot(aes(x = reorder(ID, estimate), y = estimate, ymin = .lower, ymax = .upper)) +
   geom_pointinterval(point_colour = "black", interval_color = "grey", point_alpha = .25) + scale_x_discrete("Participants ranked by posterior SD", breaks = NULL) + ylab("sigma estimate") + theme_light()
```


---


```{r}
#| code-fold: true
melsm.3 %>% 
spread_draws(b_sigma_day01, r_record_id__sigma[ID, term]) %>% 
  mutate(r_record_id__sigma = (b_sigma_day01 + r_record_id__sigma)) %>% 
   median_qi(estimate = r_record_id__sigma) %>% 
  filter(term == "day01") %>% 
  ggplot(aes(x = reorder(ID, estimate), y = estimate, ymin = .lower, ymax = .upper)) +
   geom_pointinterval(point_colour = "black", interval_color = "grey", point_alpha = .25) + scale_x_discrete("Participants ranked by posterior SD", breaks = NULL) + ylab("log slope estimate") + theme_light()
```




---


```{r}
#| code-fold: true
fits3 <- newd %>%
  add_epred_draws(melsm.3)

preds3 <- newd %>%
  add_predicted_draws(melsm.3)

fits3 %>% 
ggplot(aes(x = day01, y = N_A.std)) +
  stat_lineribbon(aes(y = .epred),.width = c(.95), alpha = 1/4, color ="grey") +
  stat_lineribbon(data = preds3, aes(y = .prediction),.width = c(.90), alpha = 1/4, color ="blue") +
  geom_point(data = newd) +
  facet_wrap(~record_id)
```



---

```{r, echo = FALSE}

preds3 %>% 
ggplot(aes(x = .prediction)) +
  stat_halfeye(aes(x = .prediction)) +
  facet_wrap(~record_id) + xlim(-3,3)

```




## Multivariate MELSM

```{r}
#| code-fold: true
melsm.4 <-
  brm(family = gaussian,
      bf(mvbind(N_A.std, P_A.std) ~ 1 + day01 + (1 + day01 |i| record_id),
         sigma ~ 1 + day01 + (1 + day01 |i| record_id)) + set_rescor(rescor = FALSE),
      prior = c(prior(normal(0, 0.2), class = Intercept, resp = NAstd),
                prior(normal(0, 1), class = b, resp = NAstd),
                prior(exponential(1), class = sd, resp = NAstd),
                prior(normal(0, 1), class = Intercept, dpar = sigma, resp = NAstd),
                prior(normal(0, 1), class = b, dpar = sigma, resp = NAstd),
                prior(exponential(1), class = sd, dpar = sigma, resp = NAstd),
                prior(normal(0, 0.2), class = Intercept, resp = PAstd),
                prior(normal(0, 1), class = b, resp = PAstd),
                prior(exponential(1), class = sd, resp = PAstd),
                prior(normal(0, 1), class = Intercept, dpar = sigma, resp = PAstd),
                prior(normal(0, 1), class = b, dpar = sigma, resp = PAstd),
                prior(exponential(1), class = sd, dpar = sigma, resp = PAstd),
                prior(lkj(2), class = cor)),
      iter = 3000, warmup = 1000, chains = 4, cores = 4,
      data = melsm,
      backend = "cmdstanr",
      file = "melsm.4")
```

---



```{r}
#| code-fold: true
summary(melsm.4)
```



---

1595 parameters estimated
```{r}
get_variables(melsm.4)
```

---

```{r}
#| code-fold: true
levels <- c("beta[0]^'NA'", "beta[1]^'NA'", "sigma[0]^'NA'", "sigma[1]^'NA'",
            "beta[0]^'PA'", "beta[1]^'PA'", "sigma[0]^'PA'", "sigma[1]^'PA'")

# two different options for ordering the parameters
# levels <- c("beta[0]^'NA'", "beta[1]^'NA'", "beta[0]^'PA'", "beta[1]^'PA'", "eta[0]^'NA'", "eta[1]^'NA'", "eta[0]^'PA'", "eta[1]^'PA'")
# levels <- c("beta[0]^'NA'", "beta[0]^'PA'", "beta[1]^'NA'", "beta[1]^'PA'","eta[0]^'NA'", "eta[0]^'PA'", "eta[1]^'NA'", "eta[1]^'PA'")

rho <-
  posterior_summary(melsm.4) %>% 
  data.frame() %>% 
  rownames_to_column("param") %>% 
  filter(str_detect(param, "cor_")) %>% 
  mutate(param = str_remove(param, "cor_record_id__")) %>% 
  separate(param, into = c("left", "right"), sep = "__") %>% 
  mutate(
    left = case_when(
      left == "NAstd_Intercept"       ~ "beta[0]^'NA'",
      left == "NAstd_day01"           ~ "beta[1]^'NA'",
      left == "sigma_NAstd_Intercept" ~ "sigma[0]^'NA'",
      left == "sigma_NAstd_day01"     ~ "sigma[1]^'NA'",
      left == "PAstd_Intercept"       ~ "beta[0]^'PA'",
      left == "PAstd_day01"           ~ "beta[1]^'PA'",
      left == "sigma_PAstd_Intercept" ~ "sigma[0]^'PA'",
      left == "sigma_PAstd_day01"     ~ "sigma[1]^'PA'"
      ),
    right = case_when(
      right == "NAstd_Intercept"       ~ "beta[0]^'NA'",
      right == "NAstd_day01"           ~ "beta[1]^'NA'",
      right == "sigma_NAstd_Intercept" ~ "sigma[0]^'NA'",
      right == "sigma_NAstd_day01"     ~ "sigma[1]^'NA'",
      right == "PAstd_Intercept"       ~ "beta[0]^'PA'",
      right == "PAstd_day01"           ~ "beta[1]^'PA'",
      right == "sigma_PAstd_Intercept" ~ "sigma[0]^'PA'",
      right == "sigma_PAstd_day01"     ~ "sigma[1]^'PA'"
    )
  ) %>% 
  mutate(label = formatC(Estimate, digits = 2, format = "f") %>% str_replace(., "0.", ".")) %>% 
  mutate(left  = factor(left, levels = levels),
         right = factor(right, levels = levels)) %>% 
  mutate(right = fct_rev(right))

rho %>% 
  full_join(rename(rho, right = left, left = right),
            by = c("left", "right", "Estimate", "Est.Error", "Q2.5", "Q97.5", "label")) %>%
  ggplot(aes(x = left, y = right)) +
  geom_tile(aes(fill = Estimate)) +
  geom_hline(yintercept = 4.5, color = "#100F14") +
  geom_vline(xintercept = 4.5, color = "#100F14") +
  geom_text(aes(label = label),
            family = "Courier", size = 3) +
  scale_fill_gradient2(expression(rho),
                       low = "#59708b", mid = "#FCF9F0", high = "#A65141", midpoint = 0,
                       labels = c(-1, "", 0, "", 1), limits = c(-1, 1)) +
  scale_x_discrete(NULL, expand = c(0, 0), labels = ggplot2:::parse_safe, position = "top") +
  scale_y_discrete(NULL, expand = c(0, 0), labels = ggplot2:::parse_safe) +
  theme(axis.text = element_text(size = 12),
        axis.ticks = element_blank(),
        legend.text = element_text(hjust = 1))

```



## Missing data

How to solve? 
1. Listwise 
2. Estimation algorithm eg FIML   
3. Multiple Imputation (before you run the model)   
4. Bayesian (while you run the model). 


## brms and multiple imputation

Each missing value is imputed N times leading to a total of N fully imputed data sets. The imputation for each dataset is similar to our predict function, using variables to make a prediction. Sometimes this is an iterative process. 

The model is then fit to  N dataset separately and results are pooled across models.

Assumes the probability that a value is missing depends only on observed values and not on unobserved values (MAR)

```{r}
#| code-fold: true

library(mice)
#multivariate imputation by chained equations

```

----

1. Replace (or impute) the missing values in each variable with temporary "place holder" values derived solely from the non-missing values available for that variable. e.g start with the mean

2. A variable at a time use the other variables (including the place holder means) to make predictions using multiple regression. E.g., find the general association, and then plug in an individuals score on those to predict the missing value. 

3. Repeat #2 with all other variables that have missing data, using the new imputated data to make predictions. 

4. Once complete, use the new imputed dataset to predict the missing values that you predicted in #2, plus some random noise. Rinse and repeat for other variables. This constitutes an iteration Do N iterations such as 5

5. Do 1-4 separately to create different imputed datasets. 

---

National Health and Nutrition Examination Survey
```{r}

data("nhanes")
nhanes
```

---

```{r}
nhanes.imp <- mice(nhanes, m = 10)
```

---

```{r}
nhanes.imp
```
mids = multiple impudated data set

ppm = predictive mean matching.  

---

One you have the 10 datasets you run the model seperate in each of them. 

Then you need to pool your estimates. 

Common issue is how to pool?
Some options: 
mice::pool() combines them Rubin's rules.
broom.mixed (another other packages) automatically incorporates the mids and does it for you



## brm_multiple

works well with mice objects, but brm_multiple also takes any list of dataframes. Helpful if you use amelia or mi. 
```{r}
imp.1 <- brm_multiple(family = gaussian,
                      bmi ~ age*chl, 
                      data = nhanes.imp,
                      cores = 4, 
                      backend = "cmdstanr",
                      file = "imp.1")
```


---

Pooling across models is trivial in a Bayesian framework but not in frequentist. 
40 Chains! 40k samples! (10 datasets + default 4 chains and 1k samples)
```{r}
summary(imp.1)
```


---

```{r}
#| code-fold: true
plot(imp.1)
```


## Revisting bayesian updating 

Remember the posterior can be thought of as a new prior for your next data acquisition. You could do this one datapoint at a time (remember globe tossing model in SR?), or a dataset at the time. 

MI is sort of like that. You could instead run 1 model with a single imputed dataset, estimate the posterior, use that posterior as a prior for a new model and then iterate through the rest of the imputed datasets


## Bayesian imputation within brms

1) Which variables contain missingness? 2) Which variables should predict missingness 3) what imputed variables are used as predictors

Taking care of this in brms ends up creating a multivariate model!
```{r}
bform <- bf(bmi | mi() ~ age * mi(chl)) +
  bf(chl | mi() ~ age) + set_rescor(FALSE)
imp.2 <- brm(bform, data = nhanes, backend = "cmdstanr", file = "imp.2")
```


---

```{r}
summary(imp.2)
```


## pro v con

Pros: Can use multilevel structure and complex non-linear relationships for the imputation of missing values, which is not achieved as easily in standard multiple imputation software

Cons: cannot impute discrete values within brms/Stan

---

```{r}
posterior_summary(imp.2)
```

## missing data posterior

```{r}
#| code-fold: true
imp.2 %>% 
  spread_draws(Ymi_chl[ID]) 
```

4000* * 10 (missing for chl) = 40,000

---


```{r}
#| code-fold: true
imp.2 %>% 
  spread_draws(Ymi_chl[ID]) %>% 
  ggplot(aes(x = Ymi_chl, 
             y = reorder(ID, Ymi_chl))) +
  stat_slab(fill = "black", alpha = 3/4, height = 1.6, slab_color = "black", slab_size = 1/4) +
  labs(x = "Chl imputed values", y = "IDs") 
```


------

```{r}
nhanes %>% 
  ggplot(aes(x=chl)) + 
  geom_density() + xlim(150,250)
```


---

```{r}
#| code-fold: true
imp.2 %>% 
  spread_draws(Ymi_bmi[ID]) %>% 
  ggplot(aes(x = Ymi_bmi, 
             y = reorder(ID, Ymi_bmi))) +
  stat_slab(fill = "black", alpha = 3/4, height = 1.6, slab_color = "black", slab_size = 1/4) +
  labs(x = "BMI imputed values", y = "IDs") +
  theme_ggdist()
```

------

```{r}
#| code-fold: true
MI <-read.csv("https://raw.githubusercontent.com/josh-jackson/bayes/master/hw3.csv")

set.seed(7474)
MI.missing <- MI %>% 
    mutate(happiness =  replace(happiness, sample(row_number(),  
           size = ceiling(0.3 * n()), replace = FALSE), NA)) %>% 
  mutate(schoool.success =  replace(schoool.success, sample(row_number(),  
           size = ceiling(0.3 * n()), replace = FALSE), NA))
MI.missing
```

-------

```{r}
summary(lm(schoool.success ~ happiness, data = MI))
```


------

```{r}
summary(lm(schoool.success ~ happiness, data = MI.missing))
```


-----


```{r}

imp.3 <- bf(schoool.success | mi() ~ mi(happiness)) +
        bf(happiness | mi() ~ friendship.quality + SES)

imp.3 <- brm(imp.3, 
    data = MI.missing, 
    iter = 2000, warmup = 1000, chains = 4, cores = 4,
    backend = "cmdstanr", 
    file = "imp.3")

```

-------

```{r}
summary(imp.3)
```

## doing it the "long" way

We could impute missing values for any variable via posterior prediction. We can set up any model with variables we think are related to the variable we want to impute. After fitting the model we can make predictions for a) people who have existing data but missing on our DV or b) completely new people who have some set of predictors. 



## measurement error

Most measurements are taken with some error, especially in psychology. 

Often require alpha > .7. Advanced approaches (SEM) use latent variables. 

When measurement error is large relative to the quantity being measured, or when very precise relations can be estimated being measured quantities, it is useful to introduce an explicit model of measurement error such as latent measurement model in SEM. 

In bayes it is related to missing data as missing value can be though of as a value with infinite measurement error. 

------

With measurement error, the insight is to realize that any uncertain piece of data can be replaced by a distribution that reflects uncertainty. 

Clastical Test Theory (CTT) defines this as: true value = observed value + error

Can think about a distribution that reflects the true value and errors around it e.g., true value is 10, but some error in. measurement y ~ N(10,2)


-----

$$\text{schoool.success (observed)} \sim \text{Normal}( \text{True.SS}_i, \text{SE.SS}_i )$$

$$\text{True.SS}_i \sim \text{Normal}(\mu_i , \sigma )$$

$\mu_i$ = $\beta_0$ + $\beta_1$ $\text{Happiness}\_c$ 

$\beta_0$ \~ Normal(0, 5)\
$\beta_1$ \~ Normal(0, 5)\
$\sigma$ \~ HalfCauchy(0,10)


-----

Where do we get the SE of the DV? What do we know about standard error of measurement?

SEM = SD * sqrt (1-reliability)
3.28 * sqrt (.7) = 2.74

```{r}
library(psych)
describe( MI)
```



-----

```{r}

ME.1 <- brm(schoool.success | mi() ~ happiness, 
            data = MI, 
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            backend = "cmdstanr", 
            file = "ME.1")

```


-------

```{r}
summary(ME.1)
```

-------------

```{r}

ME.2 <- brm(schoool.success | mi(2.74) ~ happiness, 
            data = MI, 
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            backend = "cmdstanr", 
            file = "ME.2")

```

-------

```{r}
summary(ME.2)
```


## measurement error on the predictor

me(predictor, sde_predictor)

```{r, eval = FALSE}

ME.2 <- brm(schoool.success | mi(2.74) ~ me(happiness, SD_error), 
            data = MI, 
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            backend = "cmdstanr", 
            file = "ME.2")

```


## Meta-analysis

Meta-analysis plays out statistically very much like measurement error models, where the inferences drawn from multiple data sets are combined to do inference over all of them. 

Meta analysis are also basically a multilevel model!

Learn more: https://osf.io/preprints/psyarxiv/7tbrm/

------

We can think of a meta analysis as our goal is estimating some population effect theta, with individual studies differing in how well they capture the theta. We should model each study specific error, which is easy because each sample already has this estimate. 

$$y_i \sim \operatorname{Normal}(\theta_i, \sigma_i)$$
We will not model sigma directly as we already have study specific estimates. However, if we had raw data we could use a distributional model to do so! 

------------

$$y_i \sim \operatorname{Normal}(\theta_i, \sigma_i)$$
We can break theta down into two components, a Mu which provides us estimates of the mean. And tau, which provides us the between study heterogeneity.

$$\theta_i \sim N(\mu, \tau)$$
Hopefully you can see that meta-analyses are multilevel models as this is a hyperprior where we need prior distributions for mu and tau

-------

```{r}
#| code-fold: true

spank <- read.csv("https://raw.githubusercontent.com/josh-jackson/bayes23/main/spank.csv")
spank <-
  spank %>% 
  mutate(se = (ul - ll) / 3.92)
spank 
```


-------

Modeling the difference between spanking and not spanking with cohen's d

$$ \begin{eqnarray} \text{d}_i & \sim & \text{Normal}(\theta_i, \sigma_i = \text{se}_i) \\ \theta_i & \sim & \text{Normal} (\mu, \tau) \\ \mu & \sim & \text{Normal} (0, 1) \\ \tau & \sim & \text{HalfCauchy} (0, 1) \end{eqnarray} $$

----

Each d is an estimate at the population, and we already have uncertainty estimates that we can directly incorporate into the model with the se() function. This is very similar to our MI standard error of the measurement procedure. 

```{r}
meta.1 <- 
  brm(family = gaussian,
      d | se(se) ~ 1 + (1 | study),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      data = spank, 
      backend = "cmdstanr", 
      file = "meta.1")
```

------

```{r}
summary(meta.1)
```



--------

```{r}
#| code-fold: true
get_variables(meta.1)
```


------

```{r, eval = FALSE}
#| code-fold: true
meta.1 %>%
  spread_draws(b_Intercept, r_study[study,Intercept]) 
```
Warning: Expected 2 pieces. Additional pieces discarded in 30 rows [1, 3, 9, 12, 13, 15, 16, 17, 18, 19, 23, 24, 25, 32, 38, 39, 42, 52, 60, 65, ...].Error in `spread()`:
! Each row of output must be identified by a unique combination of keys.
ℹ Keys are shared for 4 rows
• 12, 13
• 24, 25

wut?

------

We can account for this two ways. 1. modeling each estimate rather than study so as there is a random interercept for each value in the dataset. 2. Or, in this dataset, we can model each different DV as studies have two samples often have different DVs. 

```{r}

spank <- spank %>% mutate(id = row_number())


```

-----

```{r}
meta.2 <- 
  brm(family = gaussian,
      d | se(se) ~ 1 + (1 | study) + (1 | id),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      data = spank, 
      backend = "cmdstanr", 
      file = "meta.2")
```


-----

```{r}
summary(meta.2)
```

-------

```{r}
get_variables(meta.2)
```


----
```{r}
#| code-fold: true
meta.2 %>%
  spread_draws(b_Intercept, r_id[id,]) %>%
  mutate(mu = b_Intercept + r_id) %>% 
  median_qi() %>% 
  ggplot(aes(x = mu)) +
  stat_halfeye(.width = .95)
```


--------

```{r}
#| code-fold: true
meta.2 %>%
  spread_draws(b_Intercept, r_id[id,]) %>%
  mutate(mu = b_Intercept + r_id) %>%
  ggplot(aes(x = mu, y = reorder(id, mu))) +
  stat_halfeye(.width = .95, size = 2/3) +
  labs(x = expression(italic("Cohen's d")),
       y = NULL) + xlim(-.1, .8)
```
Is this what we want? 

---------

```{r}
#| code-fold: true
spank %>%
  data_grid(study, id, se)
  
```

Too many combinations once we add in epred draws, also we dont want all those levels. What do we do? 

-------

```{r}
#| code-fold: true
library(marginaleffects)
predictions(meta.2, type = "response", ndraws = 100, re_formula = NULL) %>%  posterior_draws() %>% 
  ggplot(aes(x = draw, y = reorder(study,draw))) +
  stat_halfeye(.width = .95) +
  labs(x = expression(italic("Cohen's d")),
       y = NULL) + xlim(-.1, .8)

```

-----

```{r}
#| code-fold: true

predictions(meta.2, type = "response", ndraws = 1000, re_formula = NULL) %>%  posterior_draws() %>% 
  sample_n_of(25,id) %>% 
  ggplot(aes(x = draw, y = reorder(study, draw))) +
  stat_halfeye(.width = .95) +
  labs(x = expression(italic("Cohen's d")),
       y = NULL) + xlim(-.1, 1)

```


-----

Given that some papers have multiple DVs (and not just multiple samples), we could account for this dependence 

```{r}

meta.3 <- 
  brm(family = gaussian,
      d | se(se) ~ 1 + (1 | study) + (1 | outcome) + (1 | id),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      data = spank, 
      backend = "cmdstanr", 
      file = "meta.3")

```




--------

```{r}
summary(meta.3)
```

-------

```{r}
#| code-fold: true
#| 
meta.3 %>%
  spread_draws(b_Intercept, r_outcome[outcome,]) %>%
  mutate(mu = b_Intercept + r_outcome) %>%
  ggplot(aes(x = mu, y = reorder(outcome, mu))) +
  stat_halfeye(.width = .95, size = 2/3) +
  labs(x = expression(italic("Cohen's d")),
       y = NULL) + xlim(-.1, .8)
```

-------

```{r}
#| code-fold: true
#| 
ind <- meta.3 %>%
  spread_draws(b_Intercept, r_outcome[outcome,]) %>%
  mutate(mu = b_Intercept + r_outcome)

out_all_sum <- ind %>% group_by(outcome) %>% 
      mean_qi(mu)


meta.3 %>%
  spread_draws(b_Intercept, r_outcome[outcome,]) %>%
  mutate(mu = b_Intercept + r_outcome) %>%
  ggplot(aes(x = mu, y = reorder(outcome, mu))) +
  stat_halfeye(.width = .95, size = 2/3) +
  labs(x = expression(italic("Cohen's d")),
       y = NULL) + xlim(-.1, .9)+
    geom_text(
    data = mutate_if(out_all_sum, is.numeric, round, 2),
    aes(label = glue::glue("{mu} [{.lower}, {.upper}]"), x = Inf),
    hjust = "inward")



```



## meta-regression

Can we predict these variables? 

```{r}
#| code-fold: true
meta.4 <- 
  brm(family = gaussian,
      d | se(se) ~ 1 + between + (1 | study) + (1 | outcome) + (1 | id),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      data = spank, 
      backend = "cmdstanr", 
      file = "meta.4")

```


-------

```{r}
summary(meta.4)
```




## IRT

Item response theory is no more than a regression model to predict item responses

Map items onto a latent construct. Unlike standard CTT, we assume: 
  1) items are not interchangeable. In standard approaches more items, better reliability, as there is a focus on the broad scale rather than specific items.  
  2) some items are better suited for different levels of the latent construct. E.g. a consideration of hard vs easy items 
  
## What do these regression models look like?  

Use different parameters to predict scores: 
1. Difficulty
2. Discrimination
3. Guessing 

Use different response options: 
1. Logistic
2. Categorical (mulit-nomial)
3. Graded response or partial credit (ordered categorical)
4. Ex-Gaussian and shifted lognormal distribution
5. Wiener drift diffusion model

## Item difficulty 

Difficultly is one factors that influences performance (think hard math problems). We assume that those who have high levels of the construct (cog ability, neuroticism) are more likely to correctly answer hard problems than those that are low on the construct (theta). 

An item's difficulty is defined as the trait level required for someone to have a probability of 50% correctly answering/endorsing. 

An item with a difficult of 0 (standardized values), person with a 0 theta has a 50:50 shot, whereas someone with a 1 theta will have a greater probability. For an item difficulty of 1.5, a person needs a 1.5 theta to have a 50:50 chance.   

## brms easiness

In the following code we will estimate easieness rather than difficulty. This is just the reversed scored version, all likelihood and model fit are the same. 

Why? Because it is computationally easier to do addition than subjection (see below)

## Discrimination

How well items can differentiate a person who has high theta levels from a person who has low theta levels. This is related to how strongly the item is associated with the latent construct. E.g., is it a good item? Does it have construct irrelevant content? 

Akin to item construct correlation. Or item factor loadings. 

Positive discrimination means item is associated with the latent trait. Zero means there is no association. Negative means those that score high are likely to score low on theta. 

## 1-PL (Rasch Model)

$$ y_{pi}  \sim  \text{Bernoulli}(p_{pi})$$
$$ logit(p_{pi}) = \beta_0 + \theta_p + \delta_i $$ 

(usually difficulty is defined as $\theta_p$ - $\delta_i$)

$$ \theta_p  \sim \text{Normal}(0, \sigma_\theta)$$
$$ \delta_i  \sim \text{Normal}(0, \sigma_\delta)$$

## IRT in brms

316 participants on 24 items of a questionnaire on verbal aggression. r2 is our DV and is measured Yes/No. 
```{r}
library(lme4)
data("VerbAgg", package = "lme4")
IRT <- VerbAgg
IRT
```


-------

```{r}
irt.1 <- brm(
  family = brmsfamily("bernoulli", "logit"),
  r2 ~ 1 + (1 | item) + (1 | id),
  prior = c(prior(normal(0, 3), class = Intercept),
            prior(normal(0, 3), class = "sd", group = "item"),
            prior(normal(0, 3), class = "sd", group = "id")),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
      data = IRT, 
      backend = "cmdstanr", 
      file = "irt.1")
```



------

```{r}
summary(irt.1)
```

--------

```{r}
get_variables(irt.1)
```

## Item Characteristic Curves (ICCs)

It plots the probability of endorsement as a function of latent theta. The sigmoid shape will be parallel across items in the 1pl. 

We want to specify the relevant part of the parameter space for θ, averaging across people. Since the the 1PL model has a logit link, we know most of theta will span from [-4, 4]

$$ logit(p_{pi}) = \beta_0 + \theta_p + \delta_i $$
$$ p(y = 1) = \text{logit}^{-1}(\beta_0 + \theta_p + \delta_i) $$
$$ \text{logit}^{-1} = \frac{\text{exp(x)}}{1+\text{exp(x)}}$$



----

```{r}
#| code-fold: true
irt.1 %>% 
  spread_draws(b_Intercept, r_item[item,]) %>% 
  ungroup() %>% 
  tidyr::expand(nesting(.draw, b_Intercept, item, r_item), theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + r_item + theta)) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p)) %>% 
  ggplot(aes(x = theta, y = p, color = item)) +
  geom_line() +
  labs(title = "ICCs",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1))) 
```




## Item Information Curves

They are the derivative of the item characteristic curve, and so tell us the rate of change in that probability. Same information, just a different way to look at it. 

The y axis is information. In 1pl models the IIC will have the same information shape.  


----------------

```{r}
#| code-fold: true
irt.1 %>% 
  spread_draws(b_Intercept, r_item[item,]) %>% 
  ungroup() %>% 
  tidyr::expand(nesting(.draw, b_Intercept, item, r_item), theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + r_item + theta)) %>% 
mutate(i = p * (1 - p)) %>% 
  group_by(theta, item) %>% 
  summarise(i = mean(i)) %>%
  ggplot(aes(x = theta, y = i, color = item)) +
  geom_line() +
  labs(title = "IICs",
       x = expression(theta~('ability on the logit scale')),
       y = "information") 
```



## Test Information Curve

The test information curve sums the item information scores to provide a summary of information for the full scale. We can see what levels of theta may or may not be captured by the scale. 

```{r}
#| code-fold: true
irt.1 %>% 
  spread_draws(b_Intercept, r_item[item,]) %>% 
  ungroup() %>% 
  tidyr::expand(nesting(.draw, b_Intercept, item, r_item), theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(b_Intercept + r_item + theta)) %>% 
mutate(i = p * (1 - p)) %>% 
  group_by(theta, .draw) %>% 
  summarise(sum_i = sum(i)) %>% 
  group_by(theta) %>% 
  summarise(i = median(sum_i)) %>%
  ggplot(aes(x = theta, y = i)) +
  geom_line() +
  labs(title = "The test information curve",
       x = expression(theta~('ability on the logit scale')),
       y = "information")
```


## 2PL (Two parameter logistic)

$$ y_{pi}  \sim  \text{Bernoulli}(p_{pi})$$
$$ logit(p_{pi}) =  \alpha_i(\theta_p + \delta_i) $$
Alpha is our discrimination parameter. In the 1pl it is held constant at 1. The i subscript indicates the discrimination parameter varies across the items, not across persons. 

$$ \theta_p  \sim \text{Normal}(0, \sigma_\theta)$$
$$ \delta_i  \sim \text{Normal}(0, \sigma_\delta)$$

---------

What does discrimination do? 

We will see non-parallel lines in the item characteristic terms. 

The 1pl is equivalent to setting factor loadings to 1 in SEM, where this relaxes that constraint. 


----------


![](2pl.png)


-------

While we are only predicting one parameter, p, we can think of these more complex models as similar to distributional models. That is because they will become non-linear! 

All regression models are linear in that they consist of a set of liner combinations. b1X1 X b2X2 is totally fine as interactions are linear in the parameters (they are just a parameter multiplied by a new variable X1xX2, added to other parameters) even if they are not linear in the curves the predict 

Nonlinear models are widespread and can be thought of as anything not linear e.g., B1 * B2 or cos(b1 * X). 


------

In our 2PL, we have two parameters per our repeated item measure: difficulty and discrimination, which are related in a non-linear way.

$$  p(y = 1,\alpha_i,\theta_p,\delta_i  ) =  \alpha_i(\theta_p + \delta_i) $$
We will model these much like we do distributional models but instead of distributional parameters from the likelihood, it will be different parameters from our model


## Non-linear syntax
delta was our initial modeling of difficulty. We are now also modeling how difficulty varies across discrimination, so these two terms must interact. 
Difficulty depends on the item and the person, whereas discrimination is only item specific. 
```{r}
irt.2 <- brm(
  family = brmsfamily("bernoulli", "logit"),
  bf(r2 ~ exp(logalpha) * delta, # discrimination fixed >0
    delta ~ 1 + (1 |i| item) + (1 | id),
    logalpha ~ 1 + (1 |i| item),
    nl = TRUE),
  prior = c(prior(normal(0, 1.5), class = b, nlpar = delta),
            prior(normal(0, 1), class = b, nlpar = logalpha),
            prior(student_t(10, 0, 1), class = sd, nlpar = delta),
            prior(student_t(10, 0, 1), class = sd, nlpar = logalpha),
            prior(lkj(2), class = cor)),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
    data = IRT, 
    backend = "cmdstanr", 
    file = "irt.2",
  control = list(adapt_delta = .99))

```

---------

```{r}
summary(irt.2)
```

-------

Random effect estimates for each id__delta item__delta and item__alpha
```{r}
get_variables(irt.2)
```


-----

```{r}
#| code-fold: true
irt2.dat <- irt.2 %>% 
  spread_draws(b_delta_Intercept, b_logalpha_Intercept, r_item__logalpha[item,],r_item__delta[item,]) %>% 
  ungroup() %>% 
  tidyr::expand(nesting(.draw, b_delta_Intercept, b_logalpha_Intercept, item, r_item__logalpha,r_item__delta), theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + r_item__logalpha) * (b_delta_Intercept + theta + r_item__delta)))
irt2.dat
```

--------

```{r}
#| code-fold: true
irt.2 %>% 
  spread_draws(b_delta_Intercept, b_logalpha_Intercept, r_item__logalpha[item,],r_item__delta[item,]) %>% 
  ungroup() %>% 
  tidyr::expand(nesting(.draw, b_delta_Intercept, b_logalpha_Intercept, item, r_item__logalpha,r_item__delta), theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + r_item__logalpha) * (b_delta_Intercept + theta + r_item__delta))) %>% 
  group_by(theta, item) %>% 
  summarise(p = mean(p)) %>% 
  ggplot(aes(x = theta, y = p, color = item)) +
  geom_line() +
  labs(title = "ICCs",
       x = expression(theta~('ability on the logit scale')),
       y = expression(italic(p)(y==1)))
```


---------

```{r}
#| code-fold: true
irt.2 %>% 
  spread_draws(b_delta_Intercept, b_logalpha_Intercept, r_item__logalpha[item,],r_item__delta[item,]) %>% 
  ungroup() %>% 
  tidyr::expand(nesting(.draw, b_delta_Intercept, b_logalpha_Intercept, item, r_item__logalpha,r_item__delta), theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + r_item__logalpha) * (b_delta_Intercept + theta + r_item__delta))) %>% 
  mutate(i = p * (1 - p)) %>% 
  group_by(theta, item) %>% 
  summarise(i = mean(i)) %>%
  ggplot(aes(x = theta, y = i, color = item)) +
  geom_line() +
  labs(title = "IICs",
       x = expression(theta~('ability on the logit scale')),
       y = "information") 
```


---------

```{r}
#| code-fold: true
irt.2 %>% 
  spread_draws(b_delta_Intercept, b_logalpha_Intercept, r_item__logalpha[item,],r_item__delta[item,]) %>% 
  ungroup() %>% 
  tidyr::expand(nesting(.draw, b_delta_Intercept, b_logalpha_Intercept, item, r_item__logalpha,r_item__delta), theta = seq(from = -6, to = 6, length.out = 100)) %>% 
  mutate(p = inv_logit_scaled(exp(b_logalpha_Intercept + r_item__logalpha) * (b_delta_Intercept + theta + r_item__delta))) %>% 
mutate(i = p * (1 - p)) %>% 
  group_by(theta, .draw) %>% 
  summarise(sum_i = sum(i)) %>% 
  group_by(theta) %>% 
  summarise(i = mean(sum_i)) %>%
  ggplot(aes(x = theta, y = i)) +
  geom_line() +
  labs(title = "The test information curve",
       x = expression(theta~('ability on the logit scale')),
       y = "information")
```


## Graded Response Model

From a binary setting to one in which we have multiple, ordered response categories such as with likert items. From GLM we are using the cumulative likelihood. SR refers to it as the ordered categorical.   

We want to estimate the cutpoints where someone goes from answering a 1 to a 2 or a 2 to a 3, etc. 

$$\log\left(\dfrac{Pr(y_i)}{Pr(y_i)}\right)=\log\left(\dfrac{Pr(y_i \leq k)}{1-Pr(y_i \leq k)}\right)= \alpha_k$$

-----

![](cutpoints.png)

-------

$$\text{response}_i  \sim \operatorname{cumulative} (\mathbf p) $$ $$\text{logit}(p_k)  = \alpha_k + \phi $$ 
$$\phi= 0 $$ 
$$\alpha_k \sim \operatorname{Normal}(0, 1.5)$$

Where $\phi$ is a stand in for regression terms. Right now it is an intercept only model. $\alpha_k$ are our k intercepts, make up for #categories minus 1.

---------

No, Perhaps, Yes. 

```{r}
irt.3 <- brm(
  family = brmsfamily("cumulative", "logit"),
  bf(resp ~ 1 + (1 | item) + (1 | id)),
  prior = c(prior("normal(0, 3)", class = "sd", group = "id"),
            prior("normal(0, 3)", class = "sd", group = "item")),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
    data = IRT, 
    backend = "cmdstanr", 
    file = "irt.3",
  control = list(adapt_delta = .99))
```

--------

```{r}
summary(irt.3)
```

------

```{r}
get_variables(irt.3)
```


---------

```{r}
irt.3a <- brm(
  family = brmsfamily("cumulative", "logit"),
  bf(resp | thres(gr = item) ~ 1 + (1 | item) + (1 | id)),
  prior = c(prior("normal(0, 3)", class = "sd", group = "id"),
            prior("normal(0, 3)", class = "sd", group = "item")),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
    data = IRT, 
    backend = "cmdstanr", 
    file = "irt.3a",
  control = list(adapt_delta = .99))
```


------

```{r}
summary(irt.3a)
```


------
```{r}
get_variables(irt.3a)
```

--------

```{r}
#| code-fold: true
irt.3a %>% 
gather_draws(b_Intercept[item,cut]) %>% 
  group_by(item, cut) %>% 
  summarise(mean = mean(.value),
            sd   = sd(.value),
            ll   = quantile(.value, probs = .025),
            ul   = quantile(.value, probs = .975)) %>% 
   ggplot(aes(y = factor(cut), x = mean, xmin = ll, xmax = ul, group = item, color = item)) +
  geom_pointinterval(position = position_dodge(width = -0.5)) +xlab("theta")
```


--------

```{r}
irt.4 <- brm(
  family = brmsfamily("cumulative", "logit"),
  bf(resp ~ 1 + (1 |i| item) + (1 | id),
  disc ~ 1 + (1 |i| item)),
  prior = c(prior("constant(1)", class = "sd", group = "id"), 
            prior("normal(0, 3)", class = "sd", group = "item"),
            prior("normal(0, 1)", class = "sd", group = "item", dpar = "disc")),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
    data = IRT, 
    backend = "cmdstanr", 
    file = "irt.4",
  control = list(adapt_delta = .99))


```



--------

The thresholds of two items are simply shifted to the left or right relative to each other but otherwise share the same shape



## Pros and Cons of IRT
Pro: CAT, item and people are interpreted on the same probability metric, some scores can be measured with more precision than others (rather than one reliability assessment), creation of item banks, investigation of differential item functioning (DIF)

Con: complex, CTT and IRT assessments correlate >.96, 



